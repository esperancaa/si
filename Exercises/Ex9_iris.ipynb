{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/Users/utilizador/Documents/GitHub/si/src\")\n",
    "from collections import Counter\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from si.data.dataset import Dataset\n",
    "from si.io.csv_file import read_csv\n",
    "from si.data.dataset import Dataset\n",
    "\n",
    "from si.models.decision_tree_classifier import DecisionTreeClassifier\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe RandomForestClassifier implementa o algoritmo Random Forest, um método de aprendizado de máquina supervisionado que combina múltiplas árvores de decisão para realizar classificações. Cada árvore é treinada em um subconjunto diferente dos dados com um subconjunto aleatório de características, criando um ensemble de modelos. A predição final é feita por votação majoritária entre as árvores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Random Forest__:\n",
    "Um ensemble de Árvores de Decisão onde cada árvore é treinada com:\n",
    "Um subconjunto aleatório das amostras (amostragem com reposição - bootstrap sampling).\n",
    "Um subconjunto aleatório das características (feature bagging).\n",
    "A diversidade entre as árvores reduz o risco de overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Critérios de Impureza__-:\n",
    "Gini: Mede a impureza das divisões em cada nó da árvore. Menor impureza indica melhor separação.\n",
    "Entropia: Baseada na teoria da informação, mede a incerteza de uma divisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__init__:\n",
    "Inicializa o modelo com parâmetros configuráveis, como número de árvores e profundidade.\n",
    "\n",
    "__fit__:\n",
    "Cria n_estimators árvores de decisão, cada uma treinada em um subconjunto aleatório das amostras e características.\n",
    "\n",
    "__predict__:\n",
    "Faz predições para cada árvore no ensemble e combina os resultados por votação majoritária.\n",
    "\n",
    "__score__:\n",
    "Calcula a acurácia do modelo comparando as predições com os rótulos reais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RandomForestClassifier:\n",
    "    \"\"\"\n",
    "    Random Forest Classifier: Combines multiple decision trees for classification\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_estimators=1000, max_features=None, min_samples_split=2,\n",
    "                 max_depth=10, mode='gini', seed=42):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        ----------\n",
    "        n_estimators: int - Number of decision trees.\n",
    "        max_features: int - Maximum features per tree.\n",
    "        min_samples_split: int - Minimum samples to allow a split.\n",
    "        max_depth: int - Maximum depth of the trees.\n",
    "        mode: str - Criteria for splits ('gini' or 'entropy').\n",
    "        seed: int - Random seed for reproducibility.\n",
    "        \"\"\"\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = max_features\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth  # Profundidade máxima das árvores\n",
    "        self.mode = mode # Critério de impureza para as árvores\n",
    "        self.seed = seed\n",
    "        self.trees = []  \n",
    "\n",
    "    def fit(self, dataset):\n",
    "        \"\"\"\n",
    "        Train the random forest classifier.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        dataset: Dataset - Input data to fit the model.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        self: RandomForestClassifier - Trained model.\n",
    "        \"\"\"\n",
    "        np.random.seed(self.seed)  # Ensures reproducibility\n",
    "        n_samples, n_features = dataset.shape()\n",
    "        \n",
    "        if self.max_features is None:\n",
    "            self.max_features = int(np.sqrt(n_features))\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            sample_indices = np.random.choice(n_samples, n_samples, replace=True) # Seleciona amostras com reposição (bootstrap sampling)\n",
    "            feature_indices = np.random.choice(n_features, self.max_features, replace=False)\n",
    "\n",
    "            sampled_data = Dataset(dataset.X[sample_indices][:, feature_indices], dataset.y[sample_indices])\n",
    "\n",
    "            # Inicia e treina a árvore\n",
    "            tree = DecisionTreeClassifier(\n",
    "                min_sample_split=self.min_samples_split,\n",
    "                max_depth=self.max_depth,\n",
    "                mode=self.mode\n",
    "            )\n",
    "            tree.fit(sampled_data)\n",
    "            self.trees.append((feature_indices, tree))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, dataset):\n",
    "        \"\"\"\n",
    "        Predict class labels for input dataset.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        dataset: Dataset - Input data for prediction.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        np.ndarray - Predicted class labels.\n",
    "        \"\"\"\n",
    "        n_samples = dataset.shape()[0]\n",
    "        predictions = np.zeros((self.n_estimators, n_samples), dtype=object)\n",
    "\n",
    "        for i, (feature_indices, tree) in enumerate(self.trees):\n",
    "            sampled_data = Dataset(dataset.X[:, feature_indices], dataset.y)\n",
    "            predictions[i, :] = tree.predict(sampled_data)\n",
    "\n",
    "        # Votação majoritária: Classe mais frequente para cada amostra\n",
    "        majority_vote = np.apply_along_axis(lambda x: Counter(x).most_common(1)[0][0], axis=0, arr=predictions)\n",
    "        return majority_vote\n",
    "\n",
    "    def score(self, dataset):\n",
    "        \"\"\"\n",
    "        Calculate model accuracy on dataset.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        dataset: Dataset - Input data for evaluation.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        float - Accuracy score.\n",
    "        \"\"\"\n",
    "        predictions = self.predict(dataset)\n",
    "        return np.mean(predictions == dataset.y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<si.data.dataset.Dataset at 0x140a91e50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path= \"/Users/utilizador/Documents/GitHub/si/datasets/iris/\"\n",
    "dataset = read_csv(Path + \"iris.csv\", sep=\",\", features= True, label= True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy on Test Set: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "from si.model_selection.split import stratified_train_test_split\n",
    "\n",
    "\n",
    "train_data, test_data = stratified_train_test_split(dataset, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000, min_samples_split=3, max_features=2, max_depth=3, mode='gini', seed=42)\n",
    "\n",
    "rf.fit(train_data)\n",
    "\n",
    "test_accuracy = rf.score(test_data)\n",
    "\n",
    "print(f\"Model Accuracy on Test Set: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
