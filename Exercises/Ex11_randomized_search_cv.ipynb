{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"/Users/utilizador/Documents/GitHub/si/src\")\n",
    "from si.model_selection.cross_validate import k_fold_cross_validation\n",
    "from si.io.csv_file import read_csv\n",
    "from si.data.dataset import Dataset\n",
    "from si.models.logistic_regression import LogisticRegression\n",
    "from si.model_selection.split import train_test_split\n",
    "from typing import Callable, Tuple, Dict, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função randomized_search_cv implementa uma técnica de otimização de hiperparâmetros baseada em busca aleatória. Ela testa combinações aleatórias de valores de hiperparâmetros fornecidos por meio de validação cruzada para encontrar uma configuração que maximize (ou minimize) uma métrica de desempenho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Otimização de Hiperparâmetros:__\n",
    "Hiperparâmetros são parâmetros de modelos que não são aprendidos durante o treinamento. Exemplos incluem a taxa de aprendizado em redes neurais ou o número de árvores em um Random Forest.\n",
    "A escolha correta de hiperparâmetros pode melhorar significativamente o desempenho do modelo.\n",
    "\n",
    "__Validação Cruzada (Cross-Validation):__\n",
    "Divide os dados em múltiplos subconjuntos (folds). Em cada iteração, um fold é usado como conjunto de teste enquanto os demais são usados para treinamento.\n",
    "A média das pontuações nos folds é usada como métrica de desempenho.\n",
    "\n",
    "__Busca Aleatória (Randomized Search):__\n",
    "Em vez de testar exaustivamente todas as combinações de valores (como na busca em grid), a busca aleatória seleciona combinações aleatórias. Isso reduz o custo computacional.\n",
    "\n",
    "__Componentes:__\n",
    "\n",
    "__model:__ O modelo cujo desempenho será avaliado.\n",
    "\n",
    "__dataset:__ O conjunto de dados usado para a validação cruzada.\n",
    "\n",
    "__hyperparameter_grid:__ Dicionário contendo os hiperparâmetros e seus valores possíveis.\n",
    "\n",
    "__scoring:__ Função de avaliação (como acurácia ou erro quadrático médio).\n",
    "\n",
    "__cv:__ Número de folds na validação cruzada.\n",
    "\n",
    "__n_iter:__ Número de combinações aleatórias de hiperparâmetros a testar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Validação de Entradas:__\n",
    "Verifica se o número de iterações, o grid de hiperparâmetros e o número de folds são válidos.\n",
    "Certifica-se de que o modelo possui os hiperparâmetros fornecidos.\n",
    "\n",
    "__Iterações Aleatórias:__\n",
    "Para cada iteração, escolhe uma combinação aleatória de valores de hiperparâmetros.\n",
    "Ajusta os hiperparâmetros no modelo e realiza validação cruzada.\n",
    "\n",
    "__Armazenamento de Resultados:__\n",
    "Armazena as pontuações e as combinações de hiperparâmetros testadas.\n",
    "\n",
    "__Seleção do Melhor Conjunto:__\n",
    "Identifica os hiperparâmetros e a pontuação que obtiveram o melhor desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomized_search_cv( model, dataset, hyperparameter_grid: Dict[str, Tuple], scoring: Callable = None, cv: int = 5,\n",
    "    n_iter: int = None,) :\n",
    "    \n",
    "    \"\"\"\n",
    "    Performs random search of hyperparameters with cross-validation.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    model : Model\n",
    "        The model to be evaluated.\n",
    "    dataset : Dataset\n",
    "        The dataset for cross-validation.\n",
    "    hyperparameter_grid : Dict[str, Tuple]\n",
    "        Dictionary with hyperparameters and their possible values.\n",
    "    scoring : Callable\n",
    "        Evaluation function for the model.\n",
    "    cv : int\n",
    "        Number of folds for cross-validation.\n",
    "    n_iter : int\n",
    "        Number of random combinations of hyperparameters to be tested.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    results : Dict[str, Any]\n",
    "        Results of the random search, including scores and the best hyperparameters.\n",
    "\"\"\"\n",
    "\n",
    "    # Validação dos parâmetros\n",
    "    if n_iter is None or n_iter <= 0:\n",
    "        raise ValueError(\"O número de iterações (n_iter) deve ser maior que zero.\")\n",
    "    if not hyperparameter_grid or not isinstance(hyperparameter_grid, dict):\n",
    "        raise ValueError(\"O grid de hiperparâmetros deve ser um dicionário válido.\")\n",
    "    if cv <= 1:\n",
    "        raise ValueError(\"O número de folds (cv) deve ser maior que 1.\")\n",
    "\n",
    "    # Verifica se os hiperparâmetros existem no modelo\n",
    "    for parameter in hyperparameter_grid:\n",
    "        if not hasattr(model, parameter):\n",
    "            raise AttributeError(f\"Modelo {model} não possui o hiperparâmetro '{parameter}'.\")\n",
    "\n",
    "    results = {'scores': [], 'hyperparameters': []}\n",
    "\n",
    "    for _ in range(n_iter):\n",
    "        # Seleção aleatória de valores para os hiperparâmetros\n",
    "        parameters = {key: np.random.choice(values) for key, values in hyperparameter_grid.items()}\n",
    "        for key, value in parameters.items():\n",
    "            setattr(model, key, value)  # Define o hiperparâmetro no modelo\n",
    "\n",
    "        # Validação cruzada\n",
    "        score = k_fold_cross_validation(model=model, dataset=dataset, scoring=scoring, cv=cv)\n",
    "\n",
    "        # Armazena os resultados\n",
    "        results['scores'].append(np.mean(score))\n",
    "        results['hyperparameters'].append(parameters)\n",
    "\n",
    "    # Identifica os melhores hiperparâmetros\n",
    "    best_index = np.argmax(results['scores'])\n",
    "    results['best_hyperparameters'] = results['hyperparameters'][best_index]\n",
    "    results['best_score'] = results['scores'][best_index]\n",
    "\n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.412607</td>\n",
       "      <td>3.133238</td>\n",
       "      <td>3.206304</td>\n",
       "      <td>2.809456</td>\n",
       "      <td>3.217765</td>\n",
       "      <td>3.478510</td>\n",
       "      <td>3.438395</td>\n",
       "      <td>2.866762</td>\n",
       "      <td>1.590258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var</th>\n",
       "      <td>7.909984</td>\n",
       "      <td>9.310328</td>\n",
       "      <td>8.831364</td>\n",
       "      <td>8.148507</td>\n",
       "      <td>4.901002</td>\n",
       "      <td>13.074753</td>\n",
       "      <td>5.945345</td>\n",
       "      <td>9.324655</td>\n",
       "      <td>2.940994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feat_0     feat_1     feat_2     feat_3     feat_4     feat_5  \\\n",
       "mean     4.412607   3.133238   3.206304   2.809456   3.217765   3.478510   \n",
       "median   4.000000   1.000000   1.000000   1.000000   2.000000   1.000000   \n",
       "min      1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "max     10.000000  10.000000  10.000000  10.000000  10.000000  10.000000   \n",
       "var      7.909984   9.310328   8.831364   8.148507   4.901002  13.074753   \n",
       "\n",
       "           feat_6     feat_7     feat_8  \n",
       "mean     3.438395   2.866762   1.590258  \n",
       "median   3.000000   1.000000   1.000000  \n",
       "min      1.000000   1.000000   1.000000  \n",
       "max     10.000000  10.000000  10.000000  \n",
       "var      5.945345   9.324655   2.940994  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path= \"/Users/utilizador/Documents/GitHub/si/datasets/breast_bin/\"\n",
    "data = read_csv(Path + \"breast-bin.csv\", sep=\",\", label=True)\n",
    "data.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "# Define hyperparameter distributions\n",
    "l2_penalty = np.linspace(1, 10, 10)\n",
    "alpha = np.linspace(0.001, 0.0001, 100)\n",
    "max_iter = np.linspace(1000, 2000, 200, dtype=int)\n",
    "\n",
    "parameter_grid_ = {\n",
    "        'l2_penalty': (1, 10),\n",
    "        'alpha': (0.001, 0.0001),\n",
    "        'max_iter': (1000, 2000)\n",
    "    }\n",
    "\n",
    "\n",
    "# cross validate the model\n",
    "results = randomized_search_cv(model=model,\n",
    "                              dataset=train_data,\n",
    "                              hyperparameter_grid=parameter_grid_,\n",
    "                              cv=3,\n",
    "                              n_iter=8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomized Search Results:\n",
      "Hyperparameters tested: [{'l2_penalty': np.int64(1), 'alpha': np.float64(0.001), 'max_iter': np.int64(1000)}, {'l2_penalty': np.int64(10), 'alpha': np.float64(0.001), 'max_iter': np.int64(1000)}, {'l2_penalty': np.int64(1), 'alpha': np.float64(0.0001), 'max_iter': np.int64(1000)}, {'l2_penalty': np.int64(10), 'alpha': np.float64(0.0001), 'max_iter': np.int64(2000)}, {'l2_penalty': np.int64(1), 'alpha': np.float64(0.0001), 'max_iter': np.int64(2000)}, {'l2_penalty': np.int64(1), 'alpha': np.float64(0.0001), 'max_iter': np.int64(1000)}, {'l2_penalty': np.int64(10), 'alpha': np.float64(0.0001), 'max_iter': np.int64(1000)}, {'l2_penalty': np.int64(10), 'alpha': np.float64(0.001), 'max_iter': np.int64(1000)}]\n",
      "Scores: [np.float64(0.9611451942740287), np.float64(0.9611451942740287), np.float64(0.9611451942740286), np.float64(0.9611451942740287), np.float64(0.9611451942740287), np.float64(0.9591002044989775), np.float64(0.9611451942740287), np.float64(0.9611451942740286)]\n",
      "Best Hyperparameters: {'l2_penalty': np.int64(1), 'alpha': np.float64(0.001), 'max_iter': np.int64(1000)}\n",
      "Best Score: 0.9611451942740287\n"
     ]
    }
   ],
   "source": [
    "# Output results\n",
    "print(\"Randomized Search Results:\")\n",
    "print(f\"Hyperparameters tested: {results['hyperparameters']}\")\n",
    "print(f\"Scores: {results['scores']}\")\n",
    "print(f\"Best Hyperparameters: {results['best_hyperparameters']}\")\n",
    "print(f\"Best Score: {results['best_score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
