{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.1) In the \"split.py\" module of the \"model_selection\" subpackage add the \"stratified_train_test_split\" function (Consider\n",
    "the structure of the function presented in the next slide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append(\"/Users/utilizador/Documents/GitHub/si/src\")\n",
    "from sklearn.utils import shuffle\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "from si.data.dataset import Dataset\n",
    "from si.io.csv_file import read_csv\n",
    "\n",
    "def stratified_train_test_split(dataset:Dataset, test_size=0.2, random_state:int =None) ->Tuple[Dataset, Dataset]:\n",
    "    \"\"\"\n",
    "    split the dataset into training and testing sets while maintaining the class distribution\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset: Dataset\n",
    "        The dataset to split\n",
    "    test_size: float\n",
    "        The proportion of the dataset to include in the test split\n",
    "    random_state: int\n",
    "        The seed of the random number generator\n",
    "        \n",
    "    Returns\n",
    "    train: Dataset\n",
    "        The training dataset\n",
    "    test: Dataset\n",
    "        The testing dataset\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    X= dataset.X\n",
    "    y= dataset.y\n",
    "    \n",
    "    labels = y\n",
    "    unique_classes, class_counts = np.unique(labels, return_counts=True)\n",
    "    train= []\n",
    "    test=[]\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "        \n",
    "    for label, count in zip(unique_classes, class_counts):\n",
    "        \n",
    "        idxs = np.where(labels == label)[0]\n",
    "        \n",
    "        num_test= int(np.floor(test_size * count))\n",
    "        \n",
    "        idxs= shuffle(idxs, random_state= random_state)\n",
    "        \n",
    "        lables_test_idxs= idxs[:num_test]\n",
    "        test.extend(lables_test_idxs) #use the extendo because we add multiple elements\n",
    "        \n",
    "        lables_train_idxs= idxs[num_test:]\n",
    "        train.extend(lables_train_idxs)\n",
    "    \n",
    "    train= np.array(train, dtype=int)\n",
    "    test= np.array(test, dtype=int)\n",
    "    \n",
    "    \n",
    "    X_train, X_test = X[train], X[test]\n",
    "    y_train, y_test = y[train], y[test]\n",
    "    \n",
    "    train_dataset = {'data': X_train, 'target': y_train}\n",
    "    test_dataset = {'data': X_test, 'target': y_test}\n",
    "    \n",
    "    train_dataset = Dataset(X_train, y_train, features=dataset.features, label=dataset.label)\n",
    "    test_dataset = Dataset(X_test, y_test, features=dataset.features, label=dataset.label)\n",
    "    \n",
    "    \n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var</th>\n",
       "      <td>0.681122</td>\n",
       "      <td>0.186751</td>\n",
       "      <td>3.092425</td>\n",
       "      <td>0.578532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feat_0    feat_1    feat_2    feat_3\n",
       "mean    5.843333  3.054000  3.758667  1.198667\n",
       "median  5.800000  3.000000  4.350000  1.300000\n",
       "min     4.300000  2.000000  1.000000  0.100000\n",
       "max     7.900000  4.400000  6.900000  2.500000\n",
       "var     0.681122  0.186751  3.092425  0.578532"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path= \"/Users/utilizador/Documents/GitHub/si/datasets/iris/\"\n",
    "data = read_csv(Path + \"iris.csv\", sep=\",\", label=True)\n",
    "data.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = stratified_train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
